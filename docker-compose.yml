# ==========================================================================
# Advantech GPU Passthrough Docker Compose File
# ==========================================================================
# Version:      2.0.0
# Author:       Samir Singh <samir.singh@advantech.com> and Apoorv Saxena<apoorv.saxena@advantech.com>
# Created:      January 11, 2025
# Last Updated: Dec 05, 2025
# Key Features:
#   • Full Hardware Acceleration:
#       – Direct access to CUDA, cuDNN, TensorRT, NVENC/NVDEC, and DLA
#       – Exposes all NVIDIA devices to the container
#   • Display & GUI Support:
#       – X11 forwarding with QT and EGL integration
#       – Display passthrough for accelerated OpenGL/OpenGL ES rendering
#   • Deep Learning Frameworks:
#       – Ready for PyTorch, TensorFlow, ONNX Runtime, and TensorRT workflows
#
# Terms and Conditions:
#   1. Provided by Advantech Corporation "as is," without any express or implied
#      warranties of merchantability or fitness for a particular purpose.
#   2. In no event shall Advantech Corporation be liable for any direct, indirect,
#      incidental, special, exemplary, or consequential damages arising from
#      the use of this software.
#   3. Redistribution and use in source and binary forms, with or without
#      modification, are permitted provided this notice appears in all copies.
#
# Copyright (c) 2025 Advantech Corporation. All rights reserved.
# ==========================================================================

services:
  advantech-gpu-passthrough-on-nvidia-jetson:
    image: edgesync.azurecr.io/advantech/jetson-gpu-passthrough:1.5.0-Ubuntu20.04-ARM
    container_name: GPU-Passthrough-on-NVIDIA-Jetson
    privileged: true
    ipc: host
    network_mode: host
    runtime: nvidia
    security_opt:
      - seccomp:unconfined
    tty: true
    stdin_open: true  
    entrypoint: ["/bin/bash"]
    labels:
      maintainer: "Samir Singh <samir.singh@advantech.com>"
      vendor: "Advantech Corporation"
      version: "2.0.0"
      description: "Advantech L2-02 AI development Container with hardware acceleration"
      com.advantech.jetpack: "5.1.2"
      com.advantech.cuda: "11.4"
      com.advantech.tensorrt: "8.5"
    environment:
      # Display settings
      - DISPLAY=${DISPLAY:-:0}
      - XAUTHORITY=${XAUTHORITY:-/tmp/.docker.xauth}
      - QT_X11_NO_MITSHM=1
      - XDG_RUNTIME_DIR=/tmp
      # NVIDIA settings
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=all,compute,video,utility,graphics
      # CUDA settings
      - CUDA_DEVICE_MAX_CONNECTIONS=1
      - CUDA_CACHE_DISABLE=0
      - CUDA_LAUNCH_BLOCKING=0
      # PyTorch settings
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:64
      # GStreamer settings - WARNINGS DISABLED
      - GST_DEBUG=0
      - GST_DEBUG_NO_COLOR=1
      - USE_GSTREAMER=1
      - GST_PLUGIN_SCANNER=/usr/lib/aarch64-linux-gnu/gstreamer-1.0/gst-plugin-scanner
      - GST_PLUGIN_SYSTEM_PATH=/usr/lib/aarch64-linux-gnu/gstreamer-1.0
      - GST_PLUGIN_PATH=/usr/lib/aarch64-linux-gnu/gstreamer-1.0:/usr/lib/aarch64-linux-gnu/gstreamer-1.0/deepstream
      # OpenGL/EGL settings
      - __EGL_VENDOR_LIBRARY_DIRS=/usr/share/glvnd/egl_vendor.d/:/etc/glvnd/egl_vendor.d/
      - __GLX_VENDOR_LIBRARY_NAME=nvidia
      - __GL_SYNC_TO_VBLANK=0
      - XMODIFIERS=@im=none
      - LD_LIBRARY_PATH=/usr/lib/aarch64-linux-gnu/tegra:/usr/lib/aarch64-linux-gnu/gstreamer-1.0:/usr/lib/aarch64-linux-gnu:/usr/local/cuda/lib64:${LD_LIBRARY_PATH:-}
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
    volumes:
      # Application directories (read-write)
      - ./diagnostics:/advantech/diagnostics:rw
      # Init script
      - ./init.sh:/advantech/init.sh:ro
      - ./wise-bench.sh:/advantech/wise-bench.sh:ro
      # X11 display
      - /tmp/.X11-unix:/tmp/.X11-unix:rw
      - ${XAUTHORITY:-$HOME/.Xauthority}:/tmp/.docker.xauth:rw
      - /tmp:/tmp:rw
      # Device access
      - /dev:/dev:rw
      - /sys:/sys:rw
      - /etc/nv_tegra_release:/etc/nv_tegra_release:ro
      - /usr/lib/aarch64-linux-gnu/tegra:/usr/lib/aarch64-linux-gnu/tegra:ro
      - /usr/lib/aarch64-linux-gnu/gstreamer-1.0:/usr/lib/aarch64-linux-gnu/gstreamer-1.0:ro
      - /usr/lib/aarch64-linux-gnu/tegra-egl:/usr/lib/aarch64-linux-gnu/tegra-egl:ro
      - /usr/src/jetson_multimedia_api:/usr/src/jetson_multimedia_api:ro
      - /usr/share/glvnd/egl_vendor.d/:/usr/share/glvnd/egl_vendor.d/:ro
      - /etc/glvnd/egl_vendor.d/:/etc/glvnd/egl_vendor.d/:ro
    devices:
      # NVIDIA core devices
      - /dev/nvhost-ctrl
      - /dev/nvhost-ctrl-gpu
      - /dev/nvhost-prof-gpu
      - /dev/nvmap
      - /dev/nvhost-gpu
      - /dev/nvhost-as-gpu
      # Video encode/decode
      - /dev/nvhost-vic
      - /dev/nvhost-msenc
      - /dev/nvhost-nvdec
      - /dev/nvhost-nvjpg
      # Orin-specific devices
      - /dev/nvgpu/igpu0
      - /dev/nvhost-nvdec1
      - /dev/nvhost-nvenc1
      - /dev/nvhost-nvdla0
      - /dev/nvhost-nvdla1
      # Display devices
      - /dev/nvidia-modeset
      - /dev/nvidia0
      - /dev/nvidiactl
      # Camera devices (V4L2)
      # Note: /dev/video* devices are available via /dev mount
    # Resource limits
    shm_size: '6gb'
    # Restart policy
    restart: unless-stopped
    # Working directory
    working_dir: /advantech
    # Health check
    healthcheck:
      test: ["CMD", "python3", "-c", "import onnxruntime; print('healthy')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
# ==========================================================================
# Notes:
# ==========================================================================
# 1. Run ./init.sh inside the container after first start to install
#    ONNX Runtime GPU and other dependencies.
#
# 2. For X11 display, run on host before starting container:
#    xhost +local:docker
#
# 3. To check available cameras:
#    v4l2-ctl --list-devices
#
# 4. To access container shell:
#    docker exec -it advantech-yolo-vision bash
#
# 5. For CSI cameras, use nvarguscamerasrc:
#    gst-launch-1.0 nvarguscamerasrc sensor-id=0 ! nvvidconv ! xvimagesink
# ==========================================================================
